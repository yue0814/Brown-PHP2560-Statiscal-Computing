data1 <- data.frame(matrix(1:length(unique(data$genres)),ncol = 1))
for (i in 1:length(unique(data$genres))) {
x <- unique(data$genres)[i]
data1$genres[i] <- x
data1$gross_mean[i] <- mean(data$gross[which(data$genres == x)],na.rm = TRUE)
data1$gross_se[i] <- sd(data$gross[which(data$genres == x)],na.rm = TRUE)/sqrt(length(which(data$genres == x)))
data1$profit_mean[i] <- mean(data$profit[which(data$genres == x)],na.rm = TRUE)
data1$profit_se <- sd(data$profit[which(data$genres == x)],na.rm = TRUE)/sqrt(length(which(data$genres == x)))
}
data <- data1[,2:6]
data <- data[order(data$gross_mean),]
genre_table <- cbind(genre_table,data[order(data$genres),][,c(2,4)])
data$genres <- factor(data$genres,level = data$genres)
limits <- aes(ymax = (gross_mean + gross_se)/(10**9), ymin = (gross_mean - gross_se)/(10**9))
genre_gross <- ggplot(data, aes(x = genres, y = gross_mean/(10**9), fill = genres)) +
geom_bar(stat = "identity") +scale_fill_hue(h=c(90, 20)) +
geom_errorbar(limits, colour = "black", alpha = 0.5,width = 0.3,size = 1) +
coord_flip() + theme(legend.position="none") + xlab("Genres") +
scale_y_continuous(name = "Average Gross (Billion Dollars)", limits = c(0, 0.3), breaks = seq(0,0.3,0.05)) +
ggtitle("Average Gross Gained by Movie of Difference Genres") + theme(plot.title = element_text(hjust = 0.5))
data <- data[order(data$profit_mean),]
data$genre <- factor(data$genres,level = data$genres)
limits <- aes(ymax = (profit_mean + profit_se)/(10**9), ymin = (profit_mean - profit_se)/(10**9))
genre_profit <- ggplot(data, aes(x = genre, y = profit_mean/(10**9))) +
geom_bar(aes(fill = genre),stat = "identity") +
geom_errorbar(limits, colour = "black", alpha = 0.5,width = 0.3,size = 1) +
coord_flip() + scale_fill_hue(h=c(90, 20))+ theme(legend.position="none") +
xlab("Genres") + scale_y_continuous(name = "Average Profit (Billion Dollars)", limits = c(0, 0.2), breaks = seq(0,0.2,0.05)) +
ggtitle("Average Profit Gained by Movie of Difference Genres") + theme(plot.title = element_text(hjust = 0.5))
genre_ranking <- grid.arrange(genre_gross,genre_profit,ncol = 2)
#save this graph
ggsave(file = "Genres with Highest Gross and Profit.png",plot = genre_ranking, width = 16,height = 7)
### Explore the movie genres: How gross change regards to the genres
query <- "SELECT gross,genres,title_year from movie_genre WHERE title_year > 2000 ORDER BY title_year"
data <- dbGetQuery(con, query)
genre_change<-data%>%group_by(genres,title_year)%>%summarise(total_gross=sum(gross,na.rm=TRUE)/10^9)
genre_change<-data.frame(genre_change)
genre_change[,2]<-as.character(genre_change[,2])
genre_mean <- genre_change[1:23,]
genre_mean$genres <- unique(genre_change$genres)
genre_mean$title_year <- "Mean gross \n of 15 Years"
for (x in genre_mean$genres) {
genre_mean$total_gross[genre_mean$genres == x] <-mean(genre_change$total_gross[genre_change$genres %in% x], rm.na = TRUE)
}
genre_change<-rbind(genre_change,genre_mean)
gross_genres<-ggplot(genre_change,aes(title_year,genres,fill=total_gross))+
geom_raster()+scale_fill_gradient(low="lightgoldenrod2",high="Blue")+
labs(fill="Total Gross\nfor Each Genre(Billion)")+xlab("Year")+ylab("Genres")+
ggtitle("Heatmap of Genres' Gross Change") + theme(panel.background = element_blank()) + theme(plot.title = element_text(hjust = 0.5))
#save this graph
ggsave(file = "heat map of genre.png",plot = gross_genres, width = 10, height = 7)
library(dplyr)
query <- "SELECT * FROM movie_data"
dat <- dbGetQuery(con, query)
### regression analysis
x <- dat %>%
select(aspect_ratio, cast_total_facebook_likes,facenumber_in_poster,
num_critic_for_reviews, duration, movie_facebook_likes,
director_facebook_likes, num_voted_users, actor_1_facebook_likes,
actor_2_facebook_likes, actor_3_facebook_likes, budget, gross, imdb_score)
x <- na.omit(x)
var_name <- c("aspect_ratio", "cast_total_facebook_likes", "facenumber_in_poster",
"num_critic_for_reviews", "duration", "movie_facebook_likes",
"director_facebook_likes", "num_voted_users", "actor_1_facebook_likes",
"actor_2_facebook_likes", "actor_3_facebook_likes", "budget", "gross","imdb_score")
pval <- rep(0, (length(var_name)-1))
for (i in 1:(length(var_name)-1)){
pval[i] <- summary(lm(paste0("imdb_score~", var_name[i]), data = x))$coefficients[8]
}
sig_var <- var_name[which(pval < 0.001)]  # significant variable
sum_lm <- list(0,0,0,0,0,0,0,0,0,0,0,0,0)
for (i in 1:(length(var_name)-1)){
sum_lm[[i]] <- summary(lm(paste0("imdb_score~", var_name[i]), data = x))$coefficients
}
for (i in 1:length(sum_lm)){
print(knitr::kable(as.data.frame(sum_lm[[i]])))
}
# take the significant variables to use them in the following analysis
x <- x %>%
arrange(imdb_score)
X <- subset(x, select = sig_var)
# Classification by distance analysis
# Both using Euclidean Distance
distance_analysis1 <- function(training1, training2, test = NULL){
dist2 <- function(test){
mu2 <- colMeans(scale(training2))
sqrt(rowSums((scale(test)-mu2)^2))
}
dist1 <- function(test){
mu1 <- colMeans(scale(training1))
sqrt(rowSums((scale(test)-mu1)^2))
}
if (is.null(test) == TRUE) test <- rbind(training1, training2)
nx <- nrow(test)
belong <- matrix(rep(0, nx), nrow = 1, byrow = T)
mu1 <- colMeans(training1)
S1 <- var(training1)
w <- dist2(test) - dist1(test)
for (i in 1:nx){
if (w[i] > 0){
belong[i] <- 1 # good movie
}else{belong[i] <- 2}
}
return(belong)
}
# One using Euclidean distance, the other using Mahalanobis distance
distance_analysis <- function(training1, training2, test = NULL){
dist2 <- function(test){
mu2 <- colMeans(scale(training2))
sqrt(rowSums((scale(test)-mu2)^2))
}
if (is.null(test) == TRUE) test <- rbind(training1, training2)
nx <- nrow(test)
belong <- matrix(rep(0, nx), nrow = 1, byrow = T)
mu1 <- colMeans(training1)
S1 <- var(training1)
w <- dist2(test) - mahalanobis(test, mu1, S1)
for (i in 1:nx){
if (w[i] > 0){
belong[i] <- 1 # good movie
}else{belong[i] <- 2}
}
return(belong)
}
# pull out the trainning set
# Let half of movies with imdb_score less than 8.0 as trainning set
Y <- as.matrix(X[1:median(which(x$imdb_score<8.0)), ])
# Let the movies with imdb_score larger than 8.0 as another trainning set
Z <- as.matrix(X[(max(which(x$imdb_score<8.0))+1):4171, ])
# Let the rest of movies with imdb_score less than 8.0 as testing set
test <- as.matrix(X[(median(which(x$imdb_score<8.0))+1):max(which(x$imdb_score<8.0)), ])
# classification by distance analysis
belong <- distance_analysis(Y, Z, test)
belong1 <- distance_analysis1(Y, Z, test)
# the probability of distinguishing not so good moive successfully by each distance analysis
paste0("When using both euclidean distance, the successful classification probability is ",
round(sum(belong==2)/nrow(test), digits = 4))
paste0("When using euclidean distance and mahalanobis distance,
the successful classification probability is ",
round(sum(belong1==2)/nrow(test), digits = 4))
# Regression analysis for log(year)
y <- as.matrix(table(dat$title_year))
x <-1:length(y)
z <- data.frame(x,y)
knitr::kable(summary(lm(log(y)~x,z))[[4]])
# strongly significant and R-squared = 92.6%
library(dplyr)
query <- "SELECT * FROM movie_data"
dat <- dbGetQuery(con, query)
### regression analysis
x <- dat
x <- dat %>%
select(aspect_ratio, cast_total_facebook_likes,facenumber_in_poster,
num_critic_for_reviews, duration, movie_facebook_likes,
director_facebook_likes, num_voted_users, actor_1_facebook_likes,
actor_2_facebook_likes, actor_3_facebook_likes, budget, gross, imdb_score)
x <- na.omit(x)
var_name <- c("aspect_ratio", "cast_total_facebook_likes", "facenumber_in_poster",
"num_critic_for_reviews", "duration", "movie_facebook_likes",
"director_facebook_likes", "num_voted_users", "actor_1_facebook_likes",
"actor_2_facebook_likes", "actor_3_facebook_likes", "budget", "gross","imdb_score")
pval <- rep(0, (length(var_name)-1))
for (i in 1:(length(var_name)-1)){
pval[i] <- summary(lm(paste0("imdb_score~", var_name[i]), data = x))$coefficients[8]
}
sig_var <- var_name[which(pval < 0.001)]  # significant variable
sum_lm <- list(0,0,0,0,0,0,0,0,0,0,0,0,0)
for (i in 1:(length(var_name)-1)){
sum_lm[[i]] <- summary(lm(paste0("imdb_score~", var_name[i]), data = x))$coefficients
}
for (i in 1:length(sum_lm)){
print(knitr::kable(as.data.frame(sum_lm[[i]])))
}
x <- x %>%
arrange(imdb_score)
X <- subset(x, select = sig_var)
distance_analysis1 <- function(training1, training2, test = NULL){
dist2 <- function(test){
mu2 <- colMeans(scale(training2))
sqrt(rowSums((scale(test)-mu2)^2))
}
dist1 <- function(test){
mu1 <- colMeans(scale(training1))
sqrt(rowSums((scale(test)-mu1)^2))
}
if (is.null(test) == TRUE) test <- rbind(training1, training2)
nx <- nrow(test)
belong <- matrix(rep(0, nx), nrow = 1, byrow = T)
mu1 <- colMeans(training1)
S1 <- var(training1)
w <- dist2(test) - dist1(test)
for (i in 1:nx){
if (w[i] > 0){
belong[i] <- 1 # good movie
}else{belong[i] <- 2}
}
return(belong)
}
distance_analysis <- function(training1, training2, test = NULL){
dist2 <- function(test){
mu2 <- colMeans(scale(training2))
sqrt(rowSums((scale(test)-mu2)^2))
}
if (is.null(test) == TRUE) test <- rbind(training1, training2)
nx <- nrow(test)
belong <- matrix(rep(0, nx), nrow = 1, byrow = T)
mu1 <- colMeans(training1)
S1 <- var(training1)
w <- dist2(test) - mahalanobis(test, mu1, S1)
for (i in 1:nx){
if (w[i] > 0){
belong[i] <- 1 # good movie
}else{belong[i] <- 2}
}
return(belong)
}
Y <- as.matrix(X[1:median(which(x$imdb_score<8.0)), ])
Z <- as.matrix(X[(max(which(x$imdb_score<8.0))+1):4171, ])
test <- as.matrix(X[(median(which(x$imdb_score<8.0))+1):max(which(x$imdb_score<8.0)), ])
distance_analysis(Y, Z, test)
Y <- as.matrix(X[1:median(which(x$imdb_score<8.0)), ])
# Let the movies with imdb_score larger than 8.0 as another trainning set
Z <- as.matrix(X[(max(which(x$imdb_score<8.0))+1):3801, ])
# Let the rest of movies with imdb_score less than 8.0 as testing set
test <- as.matrix(X[(median(which(x$imdb_score<8.0))+1):max(which(x$imdb_score<8.0)), ])
Y <- as.matrix(X[1:median(which(x$imdb_score<8.0)), ])
# Let the movies with imdb_score larger than 8.0 as another trainning set
Z <- as.matrix(X[(max(which(x$imdb_score<8.0))+1):(dim(X)[1]), ])
# Let the rest of movies with imdb_score less than 8.0 as testing set
test <- as.matrix(X[(median(which(x$imdb_score<8.0))+1):max(which(x$imdb_score<8.0)), ])
belong <- distance_analysis(Y, Z, test)
belong1 <- distance_analysis1(Y, Z, test)
paste0("When using both euclidean distance, the successful classification probability is ",
round(sum(belong==2)/nrow(test), digits = 4))
paste0("When using euclidean distance and mahalanobis distance,
the successful classification probability is ",
round(sum(belong1==2)/nrow(test), digits = 4))
data <- genre_change[1:340,]
data$mean_gross <- data[,3]*(10**9)
for (x in data$title_year) {
year <- data[data$title_year == x,]
genre_table[[x]] <- rep(0,26)
for (y in data$genres) {
genre_table[[x]][genre_table$genres == y] <- ifelse(length(year[year$genres == y,3]) == 0 || is.nan(year[year$genres == y,3]),  0, year[year$genres == y,3]) }
}
genre_table <- genre_table[c(1,2,3,6:21,4,5)]
names(genre_table) <- c("Genres","Number of Movies","Weights in All Genres","Mean Gross in 2001",
"Mean Gross in 2002","Mean Gross in 2003","Mean Gross in 2004",
"Mean Gross in 2005","Mean Gross in 2006","Mean Gross in 2007",
"Mean Gross in 2008","Mean Gross in 2009","Mean Gross in 2010",
"Mean Gross in 2011","Mean Gross in 2012","Mean Gross in 2013",
"Mean Gross in 2014","Mean Gross in 2015","Mean Gross in 2016",
"Mean Gross", "Mean Profit"
)
p<-tableGrob(genre_table)
p
png("test.png")
p<-tableGrob(genre_table)
grid.arrange(p)
dev.off()
ggsave(file = "genre table.png",plot = ps, width = 16, height = 9)
ggsave(file = "genre table.png",plot = p, width = 16, height = 9)
p<-grid.arrange(tableGrob(genre_table))
#save the table
ggsave(file = "genre table.png",plot = p, width = 16, height = 9)
ggsave(file = "genre table.png",plot = p, width = 26, height = 9)
png("test.pdf")
p<-tableGrob(genre_table)
grid.arrange(p)
dev.off()
pdf("test.pdf")
p<-tableGrob(genre_table)
grid.arrange(p)
dev.off()
ggsave(file = "genre table.png",plot = p, width = 36, height = 9)
ggsave(file = "genre table.png",plot = p, width = 32, height = 9)
ggsave(file = "genre table.png",plot = p, width = 34, height = 9)
ggsave(file = "genre table.png",plot = p, width = 35, height = 9)
View(genre_table)
View(genre_table)
rownames(genre_table) <- NULL
View(genre_table)
rownames(genre_table) <- NULL
p<-grid.arrange(tableGrob(genre_table))
#save the table
ggsave(file = "genre table.png",plot = p, width = 35, height = 9)
rownames(genre_table) <- NULL
p<-tableGrob(genre_table)
#save the table
ggsave(file = "genre table.png",plot = p, width = 35, height = 9)
View(genre_change)
setwd("/Users/ludanzhang/Documents/brown/statistical computing I/project 8/results")
setwd("/Users/ludanzhang/Documents/brown/statistical computing I/project 8/results")
?save
save(movie_data, file = "/Users/ludanzhang/Documents/brown/statistical computing I/project 8/results/movie.rda")
movie_dat <- read.csv(local.fn[[1]])
name <- paste("movie_data.rda")
save(movie_dat, file = paste(name))
library(DBI)
dbdir <- '/Users/ludanzhang/Documents/brown/statistical computing I/project 8/DBLite'
con <- dbConnect(MonetDBLite::MonetDBLite(), dbdir)
dbWriteTable(con, "movie_dat", movie_dat, overwrite = TRUE)
##STEP2: Clean the data
# Remove all the data of TV series
query <- "SELECT * FROM movie_dat where content_rating NOT LIKE 'TV%' "
movie_data <- dbGetQuery(con,query)
# trim whitespace
library(stringr)
movie_data$movie_title <- str_trim(movie_data$movie_title)
dbWriteTable(con,"movie_data",movie_data,overwrite = TRUE)
#Delete the repeat movies
movie_data <- movie_data[-which(duplicated(movie_data$movie_imdb_link, fromLast = TRUE)),]
#Complete the missing informaion
#scrap new information from internet
url <- read_html("http://www.the-numbers.com/movie/budgets/all")
table  <- html_table(html_nodes(url, "table"), fill = TRUE)
table <- data.frame(table)
table <- table[seq(1,dim(table)[1],2),]
#put the new data into the right form
table$Production.Budget <- as.numeric(gsub(",","",str_sub(table$Production.Budget,2,-1)))
table$Worldwide.Gross <- as.numeric(gsub(",","",str_sub(table$Worldwide.Gross,2,-1)))
table$year <- as.numeric(str_sub(table$Release.Date, -4, -1))
table = table[,-1]
#merge the new data into the former data
for (x in table$Movie) {
if (x %in% movie_data$movie_title) {
movie_data$gross[which(movie_data$movie_title == x)] <- table$Worldwide.Gross[min(which(table$Movie == x))]
movie_data$budget[which(movie_data$movie_title == x)] <- table$Production.Budget[min(which(table$Movie == x))]}
}
# save latest data to the MonetDBLite
dbWriteTable(con, "movie_data",movie_data,overwrite = TRUE)
save(movie_data, file = "/Users/ludanzhang/Documents/brown/statistical computing I/project 8/results/movie.rda")
setwd("/Users/ludanzhang/Documents/brown/statistical computing I/project 8")
save(movie_data, file = "/Users/ludanzhang/Documents/brown/statistical computing I/project 8/results/movie.rda")
library(dplyr)
load(file = "/Users/ludanzhang/Documents/brown/statistical computing I/project 8/results/movie.rda")
movie
library(dplyr)
query <- "SELECT * FROM movie_data"
dat <- dbGetQuery(con, query)
### regression analysis
x <- dat %>%
select(aspect_ratio, cast_total_facebook_likes,facenumber_in_poster,
num_critic_for_reviews, duration, movie_facebook_likes,
director_facebook_likes, num_voted_users, actor_1_facebook_likes,
actor_2_facebook_likes, actor_3_facebook_likes, budget, gross, imdb_score)
x <- na.omit(x)
var_name <- c("aspect_ratio", "cast_total_facebook_likes", "facenumber_in_poster",
"num_critic_for_reviews", "duration", "movie_facebook_likes",
"director_facebook_likes", "num_voted_users", "actor_1_facebook_likes",
"actor_2_facebook_likes", "actor_3_facebook_likes", "budget", "gross","imdb_score")
pval <- rep(0, (length(var_name)-1))
for (i in 1:(length(var_name)-1)){
pval[i] <- summary(lm(paste0("imdb_score~", var_name[i]), data = x))$coefficients[8]
}
sig_var <- var_name[which(pval < 0.001)]  # significant variable
sum_lm <- list(0,0,0,0,0,0,0,0,0,0,0,0,0)
for (i in 1:(length(var_name)-1)){
sum_lm[[i]] <- summary(lm(paste0("imdb_score~", var_name[i]), data = x))$coefficients
}
for (i in 1:length(sum_lm)){
print(knitr::kable(as.data.frame(sum_lm[[i]])))
}
x <- x %>%
arrange(imdb_score)
X <- subset(x, select = sig_var)
View(X)
View(X)
dbWriteTable(con,"genre_table",genre_table,overwrite = TRUE)
library(DBI)
dbdir <- '/Users/ludanzhang/Documents/brown/statistical computing I/project 8/DBLite'
con <- dbConnect(MonetDBLite::MonetDBLite(), dbdir)
query <- "SELECT * FROM genre_table"
genre_table <- dbGetQuery(con,query)
p<-tableGrob(genre_table)
#save the table
ggsave(file = "genre table.png",plot = p, width = 35, height = 9)
summary(movie_data)
save(genre_table,file = "genre_table.rda")
setwd("/Users/ludanzhang/Documents/brown/statistical computing I/project 8/results")
save(genre_table,file = "genre_table.rda")
genre_table[,23:24]/(10**9)
genre_table[,23:24]
genre_table[,c(23,25)]
genre_table[,c(23,24)]
genre_table[,18:19]/(10**9)
genre_table[,18:19]/(10**7)
data <- genre_change[1:340,]
data$mean_gross <- data[,3]*(10**9)
for (x in data$title_year) {
year <- data[data$title_year == x,]
genre_table[[x]] <- rep(0,26)
for (y in data$genres) {
genre_table[[x]][genre_table$genres == y] <- ifelse(length(year[year$genres == y,3]) == 0 || is.nan(year[year$genres == y,3]),  0, year[year$genres == y,3]) }
}
View(genre_table)
rm(genre_table)
data <- genre_change[1:340,]
data$mean_gross <- data[,3]*(10**9)
for (x in data$title_year) {
year <- data[data$title_year == x,]
genre_table[[x]] <- rep(0,26)
for (y in data$genres) {
genre_table[[x]][genre_table$genres == y] <- ifelse(length(year[year$genres == y,3]) == 0 || is.nan(year[year$genres == y,3]),  0, year[year$genres == y,3]) }
}
##explore the key plot words
library(wordcloud)
query <- "SELECT * FROM movie_keywords"
movie_kword <- dbGetQuery(con,query)
x1 <- movie_kword %>%
select(keyword1) %>%
group_by(keyword1) %>%
summarise(Freq = n())
x2 <-movie_kword %>%
select(keyword2) %>%
group_by(keyword2) %>%
summarise(Freq = n())
x3 <- movie_kword %>%
select(keyword3) %>%
group_by(keyword3) %>%
summarise(Freq = n())
x4 <- movie_kword %>%
select(keyword4) %>%
group_by(keyword4) %>%
summarise(Freq = n())
x5 <- movie_kword %>%
select(keyword5) %>%
group_by(keyword5) %>%
summarise(Freq = n())
names_key <-c(x1[,1], x2[,1], x3[,1], x4[,1], x5[,1])
kw_ana <- unique(unlist(names_key))
kw_ana <- kw_ana[-which(is.na(kw_ana))]
kw_count <- rep(0, length(kw_ana))
for (i in 1:length(kw_ana)){
if ( kw_ana[i] %in% as.matrix(x1[,1])){
kw_count[i] <- kw_count[i] + as.numeric(x1[which(as.matrix(x1[,1])==kw_ana[i]), 2])
}
if ( kw_ana[i] %in% as.matrix(x2[,1])){
kw_count[i] <- kw_count[i] + as.numeric(x2[which(as.matrix(x2[,1])==kw_ana[i]), 2])
}
if ( kw_ana[i] %in% as.matrix(x3[,1])){
kw_count[i] <- kw_count[i] + as.numeric(x3[which(as.matrix(x3[,1])==kw_ana[i]), 2])
}
if ( kw_ana[i] %in% as.matrix(x4[,1])){
kw_count[i] <- kw_count[i] + as.numeric(x4[which(as.matrix(x4[,1])==kw_ana[i]), 2])
}
if ( kw_ana[i] %in% as.matrix(x5[,1])){
kw_count[i] <- kw_count[i] + as.numeric(x5[which(as.matrix(x5[,1])==kw_ana[i]), 2])
}
}
colors <- c("red2", "gold2", "skyblue2")
wordcloud(kw_ana, kw_count, scale = c(4, 0.3), colors = colors,
max.words = 100, random.order = F)
png("keyplot wordcloud.png", compress = FALSE, width = 10, height= 7)
wordcloud(kw_ana, kw_count, scale = c(4, 0.3), colors = colors,
max.words = 100, random.order = F,fixed.asp = TRUE)
dev.off()
png("keyplot wordcloud.png", width = 10, height= 7)
wordcloud(kw_ana, kw_count, scale = c(4, 0.3), colors = colors,
max.words = 100, random.order = F,fixed.asp = TRUE)
dev.off()
png("keyplot wordcloud.png")
wordcloud(kw_ana, kw_count, scale = c(4, 0.3), colors = colors,
max.words = 100, random.order = F,fixed.asp = TRUE)
dev.off()
?ggsave
ggsave("try.png",wordcloud(kw_ana, kw_count, scale = c(4, 0.3), colors = colors,
max.words = 100, random.order = F,fixed.asp = TRUE))
ggsave("weight of genres.pdf",pie(percentage,labels=genre_label,col=rainbow(length(genres)),radius = 1,main="Pie Chart of Genres Weights")
)
ggsave("weight of genres.pdf",pie(percentage,labels=genre_label,col=rainbow(length(genres)),radius = 1,main="Pie Chart of Genres Weights")
,width = 10)
ggsave("weight of genres.png",pie(percentage,labels=genre_label,col=rainbow(length(genres)),radius = 1,main="Pie Chart of Genres Weights")
,width = 10)
ggsave("keyplot wordcloud.png",wordcloud(kw_ana, kw_count, scale = c(4, 0.3), colors = colors,
max.words = 100, random.order = F,fixed.asp = TRUE))
setwd("/Users/ludanzhang/Documents/brown/statistical computing I/project 8/results")
query <- "SELECT * FROM genre_table"
genre_table <- dbGetQuery(con,query)
genre_table[,18:19] <- genre_table[,18:19]/(10**7)
save(genre_table,file = "genre_table.rda")
x <- dat %>%
select(aspect_ratio, cast_total_facebook_likes,facenumber_in_poster,
num_critic_for_reviews, duration, movie_facebook_likes,
director_facebook_likes, num_voted_users, actor_1_facebook_likes,
actor_2_facebook_likes, actor_3_facebook_likes, budget, gross, imdb_score)
x <- na.omit(x)
var_name <- c("aspect_ratio", "cast_total_facebook_likes", "facenumber_in_poster",
"num_critic_for_reviews", "duration", "movie_facebook_likes",
"director_facebook_likes", "num_voted_users", "actor_1_facebook_likes",
"actor_2_facebook_likes", "actor_3_facebook_likes", "budget", "gross","imdb_score")
pval <- rep(0, (length(var_name)-1))
for (i in 1:(length(var_name)-1)){
pval[i] <- summary(lm(paste0("imdb_score~", var_name[i]), data = x))$coefficients[8]
}
sig_var <- var_name[which(pval < 0.001)]  # significant variable
sum_lm <- list(0,0,0,0,0,0,0,0,0,0,0,0,0)
for (i in 1:(length(var_name)-1)){
sum_lm[[i]] <- summary(lm(paste0("imdb_score~", var_name[i]), data = x))$coefficients
}
for (i in 1:length(sum_lm)){
knitr::kable(sum_lm[[i]])
}
knitr::kable(sum_lm[[1]])
length(sum_lm)
knitr::kable(sum_lm[[1]])
knitr::kable(sum_lm[[1]])```
github_install
uery <- "SELECT COUNT(*) AS num, title_year FROM movie_data_new WHERE title_year < 2016 GROUP BY title_year"
data <- dbGetQuery(con, query)
query <- "SELECT COUNT(*) AS num, title_year FROM movie_data_new WHERE title_year < 2016 GROUP BY title_year"
data <- dbGetQuery(con, query)
